{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f563c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LogisticRegression as LGR\n",
    "from sklearn.datasets import load_iris\n",
    "from mlxtend.plotting import plot_learning_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f2d1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification and confusion matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da39dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FinalDataset.txt')\n",
    "df = df.drop(columns = 'Number of businesses per capita')\n",
    "df = df.drop(columns = 'Number of Businesses')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42838e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all null value\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# drop the uninformatica column(\"Loan_ID\")\n",
    "df.drop(labels=['Constituency'],axis=1,inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04648bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cols = df.columns.tolist()\n",
    "for column in cols:\n",
    "    if df[column].dtype == 'object':\n",
    "        df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eafd425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:]\n",
    "y = df[\"Binary Value: NBC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07e534f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60de5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c03a7090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Median House Price ( )',\n",
       " 'Ratio of median house price to median salary',\n",
       " 'Home Ownership (proportion of households)',\n",
       " 'Unemployment Rate',\n",
       " 'Share of LSOAs (small areas) in most deprived decile',\n",
       " 'Standardised Weighted Overall Social Mobility Index',\n",
       " 'School Funding Per Pupil (Real)',\n",
       " 'Average Internet Speed (Mb/s)',\n",
       " '0-9',\n",
       " '19-Oct',\n",
       " '20-29',\n",
       " '30-39',\n",
       " '40-49',\n",
       " '50-59',\n",
       " '60-69',\n",
       " '70-79',\n",
       " '80+')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names=tuple(X.columns)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee65dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((532, 17), (532,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d01f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_other, y_train, y_other = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "X_val, X_test, y_val, y_test= train_test_split(X_other, y_other, test_size=0.50, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2187b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGR(max_iter=1000)\n",
    "sfs_code = SFS(model,\n",
    "           k_features='best', \n",
    "           forward=False, \n",
    "           floating=False, \n",
    "           verbose=0,\n",
    "               scoring='accuracy',\n",
    "               #scoring='precision',\n",
    "           #scoring='recall',\n",
    "            n_jobs=-1,\n",
    "            cv=5)\n",
    "\n",
    "sfs1 = sfs_code.fit(X_train, y_train,custom_feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f0b8fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 80.94117647058823\n",
      "Validation accuracy: 75.47169811320755\n",
      "Test accuracy: 83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "X_train_sele = sfs1.transform(X_train)\n",
    "X_val_sele = sfs1.transform(X_val)\n",
    "X_test_sele = sfs1.transform(X_test)\n",
    "\n",
    "model.fit(X_train_sele, y_train)\n",
    "print('Training accuracy:', np.mean(model.predict(X_train_sele) == y_train)*100)\n",
    "print('Validation accuracy:', np.mean(model.predict(X_val_sele) == y_val)*100)\n",
    "print('Test accuracy:', np.mean(model.predict(X_test_sele) == y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5587fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the selected feature indices at each step\n",
    "sfs1.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eec5a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs1.get_metric_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5037d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "fig1 = plot_sfs(sfs1.get_metric_dict(confidence_interval=0.95),ylabel = 'Accuracy', kind='std_err')\n",
    "plt.grid()\n",
    "plt.title('Sequential Backward Selection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86ae4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best features \n",
    "sfs1.k_feature_names_, sfs1.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0ef805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(sfs1.get_metric_dict()).T\n",
    "df[[\"feature_idx\",\"avg_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7ee86a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "class ModelSummary:\n",
    "    \"\"\" This class extracts a summary of the model\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    get_se()\n",
    "        computes standard error\n",
    "    get_ci(SE_est)\n",
    "        computes confidence intervals\n",
    "    get_pvals()\n",
    "        computes p-values\n",
    "    get_summary(name=None)\n",
    "        prints the summary of the model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, clf, X, y):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        clf: class\n",
    "            the classifier object model\n",
    "        X: pandas Dataframe\n",
    "            matrix of predictors\n",
    "        y: numpy array\n",
    "            matrix of variable\n",
    "        \"\"\"\n",
    "        self.clf = clf\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        pass\n",
    "    \n",
    "    def get_se(self):\n",
    "        # from here https://stats.stackexchange.com/questions/89484/how-to-compute-the-standard-errors-of-a-logistic-regressions-coefficients\n",
    "        predProbs = self.clf.predict_proba(self.X)\n",
    "        X_design = np.hstack([np.ones((self.X.shape[0], 1)), self.X])\n",
    "        V = np.diagflat(np.product(predProbs, axis=1))\n",
    "        covLogit = np.linalg.inv(np.dot(np.dot(X_design.T, V), X_design))\n",
    "        return np.sqrt(np.diag(covLogit))\n",
    "\n",
    "    def get_ci(self, SE_est):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        SE_est: numpy array\n",
    "            matrix of standard error estimations\n",
    "        \"\"\"\n",
    "        p = 0.975\n",
    "        df = len(self.X) - 2\n",
    "        crit_t_value = stats.t.ppf(p, df)\n",
    "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
    "        upper = coefs + (crit_t_value * SE_est)\n",
    "        lower = coefs - (crit_t_value * SE_est)\n",
    "        cis = np.zeros((len(coefs), 2))\n",
    "        cis[:,0] = lower\n",
    "        cis[:,1] = upper\n",
    "        return cis\n",
    "    \n",
    "    def get_pvals(self):\n",
    "        # from here https://stackoverflow.com/questions/25122999/scikit-learn-how-to-check-coefficients-significance\n",
    "        p = self.clf.predict_proba(self.X)\n",
    "        n = len(p)\n",
    "        m = len(self.clf.coef_[0]) + 1\n",
    "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
    "        se = self.get_se()\n",
    "        t =  coefs/se  \n",
    "        p = (1 - stats.norm.cdf(abs(t))) * 2\n",
    "        return p\n",
    "    \n",
    "    def get_summary(self, names=None):\n",
    "        ses = self.get_se()\n",
    "        cis = self.get_ci(ses)\n",
    "        lower = cis[:, 0]\n",
    "        upper = cis[:, 1]\n",
    "        pvals = self.get_pvals()\n",
    "        coefs = np.concatenate([self.clf.intercept_, self.clf.coef_[0]])\n",
    "        data = []\n",
    "        for i in range(len(coefs)):\n",
    "            currlist = []\n",
    "            currlist.append(np.round(coefs[i], 3))\n",
    "            currlist.append(np.round(ses[i], 3))\n",
    "            currlist.append(np.round(pvals[i], 3))\n",
    "            currlist.append(np.round(lower[i], 3))\n",
    "            currlist.append(np.round(upper[i], 3))\n",
    "            data.append(currlist)\n",
    "        cols = ['coefficient', 'std', 'p-value', '[0.025', '0.975]']\n",
    "        sumdf = pd.DataFrame(columns=cols, data=data)\n",
    "        if names is not None:\n",
    "            new_names = ['intercept']*(len(names) + 1)\n",
    "            new_names[1:] = [i for i in names]\n",
    "            sumdf.index = new_names\n",
    "        else:\n",
    "            try:\n",
    "                names = list(self.X.columns)\n",
    "                new_names = ['intercept']*(len(names) + 1)\n",
    "                new_names[1:] = [i for i in names]\n",
    "                sumdf.index = new_names\n",
    "            except:\n",
    "                pass\n",
    "        print(sumdf)\n",
    "        acc = accuracy_score(self.y, self.clf.predict(self.X))\n",
    "        confmat = confusion_matrix(self.y, self.clf.predict(self.X))\n",
    "        print('-'*60)\n",
    "        print('Confusion Matrix (total:{}) \\t Accuracy: \\t  {}'.format(len(self.X),np.round(acc, 3)))\n",
    "        print('  TP: {} | FN: {}'.format(confmat[1][1],confmat[1][0]))\n",
    "        print('  FP: {} | TN: {}'.format(confmat[0][1],confmat[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cbb1e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   coefficient     std  p-value  [0.025  0.975]\n",
      "0       -5.199   2.429    0.032  -9.973  -0.424\n",
      "1        0.638   0.089    0.000   0.463   0.813\n",
      "2       -0.082   1.855    0.965  -3.728   3.564\n",
      "3       -0.376  22.974    0.987 -45.533  44.781\n",
      "4       -0.805   2.574    0.754  -5.865   4.255\n",
      "5        0.006   0.004    0.111  -0.001   0.014\n",
      "6       -0.002   0.001    0.170  -0.004   0.001\n",
      "7       -0.297  10.779    0.978 -21.485  20.890\n",
      "8       -0.045  17.557    0.998 -34.556  34.466\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix (total:425) \t Accuracy: \t  0.809\n",
      "  TP: 125 | FN: 46\n",
      "  FP: 35 | TN: 219\n"
     ]
    }
   ],
   "source": [
    "#output code\n",
    "modsummary = ModelSummary(model, X_train_sele, y_train)\n",
    "modsummary.get_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
